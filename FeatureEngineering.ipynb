{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcVeeL91mca6"
      },
      "source": [
        "Подключение библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOJWyX8fmZaD",
        "outputId": "7ca875bd-bd14-4e14-b609-c1ff2896a59d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Загружен файл: emed_careers_eu.csv\n",
            "Размер исходного датасета: (39774, 8)\n",
            "Колонки: ['category', 'company_name', 'job_description', 'job_title', 'job_type', 'location', 'post_date', 'salary_offered']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Получаем имя загруженного файла\n",
        "input_filename = \"emed_careers_eu.csv\"\n",
        "print(f\"Загружен файл: {input_filename}\")\n",
        "\n",
        "# Создаем DataFrame из загруженного файла\n",
        "df = pd.read_csv(input_filename)\n",
        "print(f\"Размер исходного датасета: {df.shape}\")\n",
        "print(f\"Колонки: {list(df.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>company_name</th>\n",
              "      <th>job_description</th>\n",
              "      <th>job_title</th>\n",
              "      <th>job_type</th>\n",
              "      <th>location</th>\n",
              "      <th>post_date</th>\n",
              "      <th>salary_offered</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Clinical Research</td>\n",
              "      <td>PPD GLOBAL LTD</td>\n",
              "      <td>As part of our on-going growth, we are current...</td>\n",
              "      <td>Senior / Medical Writer (Regulatory)</td>\n",
              "      <td>Permanent</td>\n",
              "      <td>Cambridge</td>\n",
              "      <td>4/14/2018</td>\n",
              "      <td>Competitive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Science</td>\n",
              "      <td>AL Solutions</td>\n",
              "      <td>Manager of Biometrics – Italy\\nAL Solutions ar...</td>\n",
              "      <td>Manager of Biometrics</td>\n",
              "      <td>Permanent</td>\n",
              "      <td>Europe</td>\n",
              "      <td>4/16/2018</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Science</td>\n",
              "      <td>Seltek Consultants Ltd</td>\n",
              "      <td>A fantastic opportunity has arisen for an expe...</td>\n",
              "      <td>Field Service Engineer | Chromatography</td>\n",
              "      <td>Permanent</td>\n",
              "      <td>UK</td>\n",
              "      <td>4/16/2018</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Management and Statistics</td>\n",
              "      <td>Docs International UK Limited</td>\n",
              "      <td>Job Details\\n:\\nUtilise extensive clinical dat...</td>\n",
              "      <td>Data Manager of Project Management</td>\n",
              "      <td>Permanent</td>\n",
              "      <td>M4 Corridor</td>\n",
              "      <td>4/11/2018</td>\n",
              "      <td>On Application</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Science</td>\n",
              "      <td>Hyper Recruitment Solutions Ltd</td>\n",
              "      <td>Hyper Recruitment Solutions are currently look...</td>\n",
              "      <td>Strategic Market Analyst</td>\n",
              "      <td>Permanent</td>\n",
              "      <td>Cambridge</td>\n",
              "      <td>4/13/2018</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         category                      company_name  \\\n",
              "0               Clinical Research                    PPD GLOBAL LTD   \n",
              "1                         Science                      AL Solutions   \n",
              "2                         Science            Seltek Consultants Ltd   \n",
              "3  Data Management and Statistics     Docs International UK Limited   \n",
              "4                         Science   Hyper Recruitment Solutions Ltd   \n",
              "\n",
              "                                     job_description  \\\n",
              "0  As part of our on-going growth, we are current...   \n",
              "1  Manager of Biometrics – Italy\\nAL Solutions ar...   \n",
              "2  A fantastic opportunity has arisen for an expe...   \n",
              "3  Job Details\\n:\\nUtilise extensive clinical dat...   \n",
              "4  Hyper Recruitment Solutions are currently look...   \n",
              "\n",
              "                                 job_title   job_type     location  post_date  \\\n",
              "0     Senior / Medical Writer (Regulatory)  Permanent    Cambridge  4/14/2018   \n",
              "1                   Manager of Biometrics   Permanent       Europe  4/16/2018   \n",
              "2  Field Service Engineer | Chromatography  Permanent           UK  4/16/2018   \n",
              "3       Data Manager of Project Management  Permanent  M4 Corridor  4/11/2018   \n",
              "4                 Strategic Market Analyst  Permanent    Cambridge  4/13/2018   \n",
              "\n",
              "   salary_offered  \n",
              "0     Competitive  \n",
              "1             NaN  \n",
              "2             NaN  \n",
              "3  On Application  \n",
              "4             NaN  "
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 39774 entries, 0 to 39773\n",
            "Data columns (total 8 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   category         30000 non-null  object\n",
            " 1   company_name     30000 non-null  object\n",
            " 2   job_description  30000 non-null  object\n",
            " 3   job_title        30000 non-null  object\n",
            " 4   job_type         30000 non-null  object\n",
            " 5   location         30000 non-null  object\n",
            " 6   post_date        30000 non-null  object\n",
            " 7   salary_offered   22685 non-null  object\n",
            "dtypes: object(8)\n",
            "memory usage: 2.4+ MB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Index(['category', 'company_name', 'job_description', 'job_title', 'job_type',\n",
              "       'location', 'post_date', 'salary_offered'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.info()\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Пропуски по стобцам:\n",
            "category            9774\n",
            "company_name        9774\n",
            "job_description     9774\n",
            "job_title           9774\n",
            "job_type            9774\n",
            "location            9774\n",
            "post_date           9774\n",
            "salary_offered     17089\n",
            "dtype: int64\n",
            "Количество дубликатов:23022\n"
          ]
        }
      ],
      "source": [
        "print(f\"Пропуски по стобцам:\\n\" + str(df.isnull().sum()))\n",
        "print(\"Количество дубликатов:\" + str(df.duplicated().sum()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "category             18\n",
              "company_name        166\n",
              "job_description    3974\n",
              "job_title          2037\n",
              "job_type              6\n",
              "location             26\n",
              "post_date            15\n",
              "salary_offered      894\n",
              "dtype: int64"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Уникальные значения по столбцам для анализа категориальных признаков\n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Доля строк с пропусками > 90%: 24.57%\n",
            "Всего строк: 39774\n",
            "Строк с пропусками > 90%: 9774\n"
          ]
        }
      ],
      "source": [
        "X = 90  # порог в процентах\n",
        "\n",
        "# Считаем долю пропусков в каждой строке\n",
        "missing_per_row = df.isnull().sum(axis=1) / len(df.columns) * 100\n",
        "\n",
        "# Считаем, сколько строк превышают порог X%\n",
        "rows_with_many_missing = (missing_per_row > X).sum()\n",
        "\n",
        "# Доля таких строк от общего количества\n",
        "result = (rows_with_many_missing / len(df)) * 100\n",
        "\n",
        "print(f\"Доля строк с пропусками > {X}%: {result:.2f}%\")\n",
        "print(f\"Всего строк: {len(df)}\")\n",
        "print(f\"Строк с пропусками > {X}%: {rows_with_many_missing}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuPlJ4PjmgAC"
      },
      "source": [
        "Удаление дубликатов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGoyaxgMmZqy",
        "outputId": "02c4e0e9-a2c3-4d18-b4dc-9adf352d7c6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер после удаления дубликатов: (16752, 8)\n",
            "Строковые поля очищены от пробелов\n"
          ]
        }
      ],
      "source": [
        "# Удаляем все дубликаты строк\n",
        "df = df.drop_duplicates()\n",
        "print(f\"Размер после удаления дубликатов: {df.shape}\")\n",
        "\n",
        "# Очищаем строковые колонки от пробелов в начале и конце\n",
        "for c in df.columns:\n",
        "    if df[c].dtype == \"object\":\n",
        "        df[c] = df[c].astype(\"string\").str.strip()\n",
        "\n",
        "print(\"Строковые поля очищены от пробелов\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Пропуски по стобцам:\n",
            "category              1\n",
            "company_name          1\n",
            "job_description       1\n",
            "job_title             1\n",
            "job_type              1\n",
            "location              1\n",
            "post_date             1\n",
            "salary_offered     4235\n",
            "dtype: int64\n",
            "Количество дубликатов:0\n"
          ]
        }
      ],
      "source": [
        "print(f\"Пропуски по стобцам:\\n\" + str(df.isnull().sum()))\n",
        "print(\"Количество дубликатов:\" + str(df.duplicated().sum()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE2G4INRmiNC"
      },
      "source": [
        "Нормализация названий компаний и локаций"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXB2U-fxmZxa",
        "outputId": "1b583da7-1a9a-4e77-a744-3505860c0e07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Названия компаний нормализованы\n",
            "Локации нормализованы\n"
          ]
        }
      ],
      "source": [
        "# Нормализует текстовое значение:\n",
        "#   Заменяет пропущенные значения на \"UNKNOWN\"\n",
        "#   Удаляет лишние пробелы\n",
        "#   Удаляет все символы кроме букв, цифр и пробелов\n",
        "#   Приводит к верхнему регистру\n",
        "def normalize_token(val) -> str:\n",
        "    if pd.isna(val):\n",
        "        return \"UNKNOWN\"\n",
        "    s = str(val).strip()\n",
        "    if s == \"\" or s.lower() in {\"nan\", \"none\"}:\n",
        "        return \"UNKNOWN\"\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    s = re.sub(r\"[^A-Za-z0-9 ]+\", \"\", s)\n",
        "    s = s.strip().upper()\n",
        "    return s if s else \"UNKNOWN\"\n",
        "\n",
        "# Применяем нормализацию к company_name\n",
        "if \"company_name\" in df.columns:\n",
        "    df[\"company_name\"] = df[\"company_name\"].apply(normalize_token)\n",
        "    print(\"Названия компаний нормализованы\")\n",
        "\n",
        "# Применяем нормализацию к location\n",
        "if \"location\" in df.columns:\n",
        "    df[\"location\"] = df[\"location\"].apply(normalize_token)\n",
        "    # Специальные замены для локаций\n",
        "    df[\"location\"] = df[\"location\"].replace({\"UK2\": \"UK\", \"U K\": \"UK\"})\n",
        "    print(\"Локации нормализованы\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTcIfDW2mita"
      },
      "source": [
        "Обработка дат публикации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYDKBsZCmZ2q",
        "outputId": "097d2023-7611-48f0-9ece-b04eff4c779f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Компоненты даты извлечены\n",
            "Диапазон дат: с 2018-04-03 00:00:00 по 2018-04-17 00:00:00\n"
          ]
        }
      ],
      "source": [
        "if \"post_date\" in df.columns:\n",
        "    # Преобразуем строки в datetime\n",
        "    df[\"post_date\"] = pd.to_datetime(df[\"post_date\"], errors=\"coerce\")\n",
        "\n",
        "    # Извлекаем компоненты даты\n",
        "    df[\"post_year\"] = df[\"post_date\"].dt.year\n",
        "    df[\"post_month\"] = df[\"post_date\"].dt.month\n",
        "    df[\"post_day\"] = df[\"post_date\"].dt.day\n",
        "    df[\"post_dayofweek\"] = df[\"post_date\"].dt.dayofweek\n",
        "\n",
        "    print(\"Компоненты даты извлечены\")\n",
        "    print(f\"Диапазон дат: с {df['post_date'].min()} по {df['post_date'].max()}\")\n",
        "else:\n",
        "    print(\"Колонка 'post_date' не найдена\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O82uwnqOmjKK"
      },
      "source": [
        "Анализ описаний вакансий"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jrlk3QimZ8S",
        "outputId": "703b7627-3ab2-43d4-e8de-2ee24d1ab440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Средняя длина описания: 2420 символов\n",
            "Среднее количество слов: 358\n",
            "Создано 13 признаков на основе ключевых слов\n",
            "\n",
            "Частота встречаемости ключевых слов:\n",
            "  kw_senior: 58.1%\n",
            "  kw_manager: 47.7%\n",
            "  kw_bonus: 28.2%\n",
            "  kw_junior: 15.8%\n",
            "  kw_english: 15.8%\n",
            "  kw_phd: 8.7%\n",
            "  kw_remote: 5.3%\n",
            "  kw_german: 5.3%\n",
            "  kw_visa: 3.5%\n",
            "  kw_french: 2.1%\n",
            "  kw_sql: 0.9%\n",
            "  kw_ml: 0.7%\n",
            "  kw_python: 0.4%\n"
          ]
        }
      ],
      "source": [
        "if \"job_description\" in df.columns:\n",
        "    s = df[\"job_description\"].fillna(\"\").astype(\"string\")\n",
        "\n",
        "    # Базовые метрики описания\n",
        "    df[\"desc_len\"] = s.str.len()\n",
        "    df[\"desc_word_count\"] = s.str.split().str.len()\n",
        "\n",
        "    print(f\"Средняя длина описания: {df['desc_len'].mean():.0f} символов\")\n",
        "    print(f\"Среднее количество слов: {df['desc_word_count'].mean():.0f}\")\n",
        "\n",
        "    # Паттерны для поиска ключевых слов\n",
        "    patterns = {\n",
        "        \"kw_remote\": r\"\\bremote\\b|\\bwork from home\\b|\\bwfh\\b|\\bhybrid\\b\",\n",
        "        \"kw_bonus\": r\"\\bbonus\\b|\\bcommission\\b|\\bperformance\\b\",\n",
        "        \"kw_senior\": r\"\\bsenior\\b|\\blead\\b|\\bstaff\\b|\\bprincipal\\b\",\n",
        "        \"kw_junior\": r\"\\bjunior\\b|\\bentry\\b|\\bgraduate\\b|\\bintern\\b\",\n",
        "        \"kw_manager\": r\"\\bmanager\\b|\\bhead of\\b|\\bdirector\\b\",\n",
        "        \"kw_english\": r\"\\benglish\\b\",\n",
        "        \"kw_german\": r\"\\bgerman\\b|\\bdeutsch\\b\",\n",
        "        \"kw_french\": r\"\\bfrench\\b|\\bfran[cç]ais\\b\",\n",
        "        \"kw_visa\": r\"\\bvisa\\b|\\brelocation\\b|\\bsponsorship\\b\",\n",
        "        \"kw_python\": r\"\\bpython\\b\",\n",
        "        \"kw_sql\": r\"\\bsql\\b\",\n",
        "        \"kw_ml\": r\"\\bmachine learning\\b|\\bdeep learning\\b|\\bartificial intelligence\\b|\\b ai\\b\",\n",
        "        \"kw_phd\": r\"\\bphd\\b|\\bdoctorate\\b\",\n",
        "    }\n",
        "\n",
        "    # Создаем бинарные признаки для каждого паттерна\n",
        "    for feat, pat in patterns.items():\n",
        "        df[feat] = s.str.contains(pat, case=False, regex=True, na=False).astype(int)\n",
        "\n",
        "    print(f\"Создано {len(patterns)} признаков на основе ключевых слов\")\n",
        "\n",
        "    # Выводим статистику по найденным ключевым словам\n",
        "    kw_cols = [col for col in df.columns if col.startswith('kw_')]\n",
        "    kw_stats = df[kw_cols].mean().sort_values(ascending=False)\n",
        "    print(\"\\nЧастота встречаемости ключевых слов:\")\n",
        "    for kw, freq in kw_stats.items():\n",
        "        print(f\"  {kw}: {freq:.1%}\")\n",
        "else:\n",
        "    print(\"Колонка 'job_description' не найдена\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG_w4VKbmjoS"
      },
      "source": [
        "Анализ названий должностей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93DaUW7BmaHS",
        "outputId": "22ebfa3a-e540-49ea-9335-0b2b1800d523"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Средняя длина названия: 26 символов\n",
            "Среднее количество слов: 3\n",
            "Должности с признаком senior: 3410 (20.4%)\n",
            "Должности с признаком junior: 272 (1.6%)\n",
            "Должности с признаком manager: 6154 (36.7%)\n"
          ]
        }
      ],
      "source": [
        "if \"job_title\" in df.columns:\n",
        "    t = df[\"job_title\"].fillna(\"\").astype(\"string\")\n",
        "\n",
        "    # Базовые метрики названия\n",
        "    df[\"title_len\"] = t.str.len()\n",
        "    df[\"title_word_count\"] = t.str.split().str.len()\n",
        "\n",
        "    print(f\"Средняя длина названия: {df['title_len'].mean():.0f} символов\")\n",
        "    print(f\"Среднее количество слов: {df['title_word_count'].mean():.0f}\")\n",
        "\n",
        "    # Определяем уровень должности по названию\n",
        "    df[\"title_has_senior\"] = t.str.contains(r\"\\bsenior\\b|\\blead\\b|\\bprincipal\\b|\\bstaff\\b\", case=False, regex=True, na=False).astype(int)\n",
        "    df[\"title_has_junior\"] = t.str.contains(r\"\\bjunior\\b|\\bintern\\b|\\bgraduate\\b|\\bentry\\b\", case=False, regex=True, na=False).astype(int)\n",
        "    df[\"title_has_manager\"] = t.str.contains(r\"\\bmanager\\b|\\bdirector\\b|\\bhead\\b\", case=False, regex=True, na=False).astype(int)\n",
        "\n",
        "    print(f\"Должности с признаком senior: {df['title_has_senior'].sum()} ({df['title_has_senior'].mean():.1%})\")\n",
        "    print(f\"Должности с признаком junior: {df['title_has_junior'].sum()} ({df['title_has_junior'].mean():.1%})\")\n",
        "    print(f\"Должности с признаком manager: {df['title_has_manager'].sum()} ({df['title_has_manager'].mean():.1%})\")\n",
        "else:\n",
        "    print(\"Колонка 'job_title' не найдена\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL5rsx31mkDR"
      },
      "source": [
        "Извлечение зарплатных данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtPtDb5imaKc",
        "outputId": "f5316a95-46bd-4f73-bdcd-21b8436777a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Зарплата указана в 12517 вакансиях (74.7%)\n",
            "Числовые значения найдены в 2988 вакансиях\n",
            "Средняя минимальная зарплата: 41055\n",
            "Средняя максимальная зарплата: 49941\n",
            "Формулировка 'competitive' встречается в 35.6% случаев\n"
          ]
        }
      ],
      "source": [
        "# Извлекает информацию о зарплате из текстового описания:\n",
        "#     - Находит числовые значения\n",
        "#     - Определяет минимальную и максимальную зарплату\n",
        "#     - Определяет, указана ли зарплата как \"конкурентная\"\n",
        "def extract_salary_range(text):\n",
        "    if pd.isna(text):\n",
        "        return (np.nan, np.nan, 0, 0)\n",
        "    s = str(text).lower().strip()\n",
        "\n",
        "    # Проверяем на наличие слов, указывающих на отсутствие конкретной суммы\n",
        "    competitive_words = [\"competitive\", \"not disclosed\", \"negotiable\", \"depending\", \"doe\", \"tbd\"]\n",
        "    is_competitive = int(any(w in s for w in competitive_words))\n",
        "\n",
        "    # Обрабатываем сокращения с \"k\" (например, \"50k\" -> 50000)\n",
        "    s = re.sub(r\"(\\d+)\\s*k\\b\", lambda m: str(int(m.group(1)) * 1000), s)\n",
        "    s = re.sub(r\"(\\d)\\s+(\\d)\", r\"\\1\\2\", s)\n",
        "\n",
        "    # Извлекаем все числа\n",
        "    nums = re.findall(r\"\\d[\\d,]*\", s)\n",
        "    nums = [n.replace(\",\", \"\") for n in nums if n.replace(\",\", \"\").isdigit()]\n",
        "    nums = [int(n) for n in nums]\n",
        "\n",
        "    if len(nums) >= 2:\n",
        "        return (nums[0], nums[1], is_competitive, 1)\n",
        "    if len(nums) == 1:\n",
        "        return (nums[0], np.nan, is_competitive, 1)\n",
        "    return (np.nan, np.nan, is_competitive, 0)\n",
        "\n",
        "if \"salary_offered\" in df.columns:\n",
        "    # Создаем признаки на основе зарплатных данных\n",
        "    df[\"salary_provided\"] = df[\"salary_offered\"].notna().astype(int)\n",
        "    ext = df[\"salary_offered\"].apply(extract_salary_range)\n",
        "    df[\"salary_min\"] = ext.apply(lambda x: x[0])\n",
        "    df[\"salary_max\"] = ext.apply(lambda x: x[1])\n",
        "    df[\"salary_is_competitive\"] = ext.apply(lambda x: x[2])\n",
        "    df[\"salary_numeric_found\"] = ext.apply(lambda x: x[3])\n",
        "    df[\"salary_avg\"] = df[[\"salary_min\", \"salary_max\"]].mean(axis=1)\n",
        "\n",
        "    print(f\"Зарплата указана в {df['salary_provided'].sum()} вакансиях ({df['salary_provided'].mean():.1%})\")\n",
        "    print(f\"Числовые значения найдены в {df['salary_numeric_found'].sum()} вакансиях\")\n",
        "    print(f\"Средняя минимальная зарплата: {df['salary_min'].mean():.0f}\")\n",
        "    print(f\"Средняя максимальная зарплата: {df['salary_max'].mean():.0f}\")\n",
        "    print(f\"Формулировка 'competitive' встречается в {df['salary_is_competitive'].mean():.1%} случаев\")\n",
        "else:\n",
        "    print(\"Колонка 'salary_offered' не найдена\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F09XQXHTmkeS"
      },
      "source": [
        "Кодирование категориальных признаков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DPlLgpGmaNC",
        "outputId": "8dab6cbc-cd40-409f-c8c6-69e7246e3631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Добавлена категориальная колонка: category\n",
            "Добавлена категориальная колонка: job_type\n",
            "Компании: оставлено 81 уникальных значений (включая OTHER)\n",
            "Локации: оставлено 20 уникальных значений (включая OTHER)\n",
            "\n",
            "Размер после one-hot encoding: (16752, 155)\n",
            "Количество признаков увеличилось с 38 до 155\n"
          ]
        }
      ],
      "source": [
        "# Оставляет только n самых частых значений, остальные заменяет на \"OTHER\"\n",
        "def top_n_other(series, n=80):\n",
        "    series = series.fillna(\"UNKNOWN\").astype(\"string\")\n",
        "    top = series.value_counts().nlargest(n).index\n",
        "    return series.where(series.isin(top), other=\"OTHER\")\n",
        "\n",
        "TOP_N_COMPANIES = 80\n",
        "TOP_N_LOCATIONS = 80\n",
        "\n",
        "cat_cols = []\n",
        "\n",
        "# Добавляем стандартные категориальные колонки\n",
        "for col in [\"category\", \"job_type\"]:\n",
        "    if col in df.columns:\n",
        "        cat_cols.append(col)\n",
        "        print(f\"Добавлена категориальная колонка: {col}\")\n",
        "\n",
        "# Обрабатываем company_name (оставляем топ-80)\n",
        "if \"company_name\" in df.columns:\n",
        "    df[\"company_name\"] = top_n_other(df[\"company_name\"], n=TOP_N_COMPANIES)\n",
        "    cat_cols.append(\"company_name\")\n",
        "    unique_companies = df[\"company_name\"].nunique()\n",
        "    print(f\"Компании: оставлено {unique_companies} уникальных значений (включая OTHER)\")\n",
        "\n",
        "# Обрабатываем location (оставляем топ-80)\n",
        "if \"location\" in df.columns:\n",
        "    df[\"location\"] = top_n_other(df[\"location\"], n=TOP_N_LOCATIONS)\n",
        "    cat_cols.append(\"location\")\n",
        "    unique_locations = df[\"location\"].nunique()\n",
        "    print(f\"Локации: оставлено {unique_locations} уникальных значений (включая OTHER)\")\n",
        "\n",
        "# Создаем dummy-переменные (one-hot encoding)\n",
        "df_processed = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
        "print(f\"\\nРазмер после one-hot encoding: {df_processed.shape}\")\n",
        "print(f\"Количество признаков увеличилось с {df.shape[1]} до {df_processed.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9RpVcuvq4tP"
      },
      "source": [
        "Удаление исходных текстовых колонок"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFA84aJbq3zX",
        "outputId": "50a0db13-f3d0-437e-8c34-30d5b211f06d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Удалены колонки: ['post_date', 'job_description', 'job_title', 'salary_offered']\n",
            "Размер после удаления: (16752, 151)\n"
          ]
        }
      ],
      "source": [
        "columns_to_drop = [c for c in [\"post_date\", \"job_description\", \"job_title\", \"salary_offered\"]\n",
        "                   if c in df_processed.columns]\n",
        "\n",
        "df_processed = df_processed.drop(columns=columns_to_drop, errors=\"ignore\")\n",
        "print(f\"Удалены колонки: {columns_to_drop}\")\n",
        "print(f\"Размер после удаления: {df_processed.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9myZvFpq_0m"
      },
      "source": [
        "Преобразование типов и обработка пропусков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOibT92RrAlm",
        "outputId": "9558992f-616c-4521-a632-91f0f75f3616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Преобразовано 121 булевых колонок в целые числа\n"
          ]
        }
      ],
      "source": [
        "# Преобразуем boolean в int (0/1)\n",
        "bool_cols = df_processed.select_dtypes(include=[\"bool\"]).columns\n",
        "df_processed[bool_cols] = df_processed[bool_cols].astype(int)\n",
        "if len(bool_cols) > 0:\n",
        "    print(f\"Преобразовано {len(bool_cols)} булевых колонок в целые числа\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Заполняем пропуски в числовых колонках медианными значениями\n",
        "#num_cols = df_processed.select_dtypes(include=[np.number]).columns\n",
        "#df_processed[num_cols] = df_processed[num_cols].fillna(df_processed[num_cols].median(numeric_only=True))\n",
        "#print(f\"Заполнены пропуски в {len(num_cols)} числовых колонках\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip3 -q install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для каждой колонки с пропусками строится модель регрессии, которая предсказывает пропущенные значения на основе всех остальных колонок\n",
        "\n",
        "Итеративный процесс:\n",
        "\n",
        "    1: Временно заполняет пропуски простыми значениями (среднее/медиана)\n",
        "\n",
        "    2: Для колонки A строит модель, используя все остальные колонки как признаки\n",
        "\n",
        "    3: Предсказывает и обновляет значения в колонке A\n",
        "\n",
        "    4: Переходит к колонке B, теперь используя обновленную колонку A\n",
        "\n",
        "Повторяет 20 раз (max_iter=20), пока значения не стабилизируются\n",
        "\n",
        "sample_posterior=True добавляет случайный шум, чтобы имитировать естественную вариативность данных (а не просто предсказывать точное значение)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MICE-импутация выполнена для 151 числовых колонок\n"
          ]
        }
      ],
      "source": [
        "# Заполняем пропуски в числовых колонках \n",
        "from sklearn.experimental import enable_iterative_imputer \n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "# Выбираем числовые колонки\n",
        "num_cols = df_processed.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# Создаём MICE-импутер\n",
        "mice = IterativeImputer(\n",
        "    max_iter=20,\n",
        "    random_state=42,\n",
        "    sample_posterior=True\n",
        ")\n",
        "\n",
        "# Применяем только к числовым колонкам\n",
        "df_processed[num_cols] = mice.fit_transform(df_processed[num_cols])\n",
        "\n",
        "print(f\"MICE-импутация выполнена для {len(num_cols)} числовых колонок\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Все колонки успешно преобразованы в числовой формат\n",
            "\n",
            "Итоговый размер датасета: (16752, 151)\n",
            "Типы данных:\n",
            "float64    151\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Удаляем оставшиеся нечисловые колонки\n",
        "non_num_cols = df_processed.select_dtypes(exclude=[np.number]).columns\n",
        "if len(non_num_cols) > 0:\n",
        "    print(f\"Удалены нечисловые колонки: {list(non_num_cols)}\")\n",
        "    df_processed = df_processed.drop(columns=non_num_cols, errors=\"ignore\")\n",
        "else:\n",
        "    print(\"Все колонки успешно преобразованы в числовой формат\")\n",
        "\n",
        "print(f\"\\nИтоговый размер датасета: {df_processed.shape}\")\n",
        "print(f\"Типы данных:\\n{df_processed.dtypes.value_counts()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiDHYPUfrMWe"
      },
      "source": [
        "Сохранение и скачивание обработанного датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "lXqrOwAarMeO",
        "outputId": "c860670f-b926-464f-e033-5549fe90bf48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Файл сохранен как: processed_dataset.csv\n",
            "Размер файла: 19.43 MB\n",
            "\n",
            "Первые 5 строк обработанного датасета:\n",
            "   post_year  post_month  post_day  post_dayofweek  desc_len  desc_word_count  \\\n",
            "0     2018.0         4.0      14.0             5.0    2522.0            359.0   \n",
            "1     2018.0         4.0      16.0             0.0    1875.0            291.0   \n",
            "2     2018.0         4.0      16.0             0.0    2523.0            374.0   \n",
            "3     2018.0         4.0      11.0             2.0    2021.0            279.0   \n",
            "4     2018.0         4.0      13.0             4.0    1467.0            210.0   \n",
            "\n",
            "   kw_remote  kw_bonus  kw_senior  kw_junior  ...  location_NORTH WEST  \\\n",
            "0        0.0       0.0        1.0        0.0  ...                  0.0   \n",
            "1        1.0       0.0        1.0        1.0  ...                  0.0   \n",
            "2        0.0       0.0        0.0        0.0  ...                  0.0   \n",
            "3        1.0       1.0        1.0        0.0  ...                  0.0   \n",
            "4        0.0       0.0        0.0        0.0  ...                  0.0   \n",
            "\n",
            "   location_OXFORD  location_PARIS  location_PORTUGAL  location_SCOTLAND  \\\n",
            "0              0.0             0.0                0.0                0.0   \n",
            "1              0.0             0.0                0.0                0.0   \n",
            "2              0.0             0.0                0.0                0.0   \n",
            "3              0.0             0.0                0.0                0.0   \n",
            "4              0.0             0.0                0.0                0.0   \n",
            "\n",
            "   location_SOUTH EAST  location_SPAIN  location_SWITZERLAND  location_UK  \\\n",
            "0                  0.0             0.0                   0.0          0.0   \n",
            "1                  0.0             0.0                   0.0          0.0   \n",
            "2                  0.0             0.0                   0.0          1.0   \n",
            "3                  0.0             0.0                   0.0          0.0   \n",
            "4                  0.0             0.0                   0.0          0.0   \n",
            "\n",
            "   location_UNKNOWN  \n",
            "0               0.0  \n",
            "1               0.0  \n",
            "2               0.0  \n",
            "3               0.0  \n",
            "4               0.0  \n",
            "\n",
            "[5 rows x 151 columns]\n"
          ]
        }
      ],
      "source": [
        "out_name = \"processed_emed_careers_eu.csv\"\n",
        "df_processed.to_csv(out_name, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(f\"Файл сохранен как: {out_name}\")\n",
        "print(f\"Размер файла: {df_processed.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "print(\"\\nПервые 5 строк обработанного датасета:\")\n",
        "print(df_processed.head())\n",
        "\n",
        "df_processed.to_csv(out_name, index=False, encoding=\"utf-8\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
